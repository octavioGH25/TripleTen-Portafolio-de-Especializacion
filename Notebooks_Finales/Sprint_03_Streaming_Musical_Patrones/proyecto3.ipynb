{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√≥dulo de Auditor√≠a 03: Comparativa de Patrones de Consumo (Music Streaming)\n",
    "## üõ°Ô∏è Contexto del An√°lisis\n",
    "En este proyecto, se trabaja con datos reales de transmisi√≥n de m√∫sica online para explorar los h√°bitos de escucha en Springfield y Shelbyville. El objetivo es auditar si la actividad de los usuarios presenta variaciones significativas seg√∫n el d√≠a de la semana y la ubicaci√≥n geogr√°fica.\n",
    "\n",
    "## üéØ Objetivos de la Auditor√≠a\n",
    "1.  **Descripci√≥n de Datos:** Evaluar la calidad de la muestra inicial y detectar problemas en la metadata (nombres de columnas, tipos de datos).\n",
    "2.  **Preprocesamiento:** Limpiar los datos abordando valores duplicados y ausentes para asegurar la integridad del an√°lisis.\n",
    "3.  **Prueba de Hip√≥tesis:** Analizar el comportamiento de los usuarios los d√≠as lunes, mi√©rcoles y viernes para determinar si existen diferencias culturales de consumo entre ambas ciudades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# D√©jame escuchar m√∫sica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Contenido <a id='back'></a>\n",
    "\n",
    "* [Introducci√≥n](#intro)\n",
    "* [Etapa 1. Descripci√≥n de los datos](#data_review)\n",
    "    * [Conclusiones](#data_review_conclusions)\n",
    "* [Etapa 2. Preprocesamiento de datos](#data_preprocessing)\n",
    "    * [2.1 Estilo del encabezado](#header_style)\n",
    "    * [2.5 Valores ausentes](#missing_values)\n",
    "    * [2.8 Duplicados](#duplicates)\n",
    "    * [2.14 Conclusiones](#data_preprocessing_conclusions)\n",
    "* [Etapa 3. Prueba de hip√≥tesis](#hypothesis)\n",
    "    * [3.1 Tarea: Comparar el comportamiento de los usuarios en las dos ciudades](#activity)\n",
    "* [Conclusiones](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "# Introducci√≥n <a id='intro'></a>\n",
    "Como analista de datos, tu trabajo consiste en analizar datos para extraer informaci√≥n valiosa de ellos y tomar decisiones en consecuencia. Esto implica pasar por diferentes etapas, como la descripci√≥n general de los datos, el preprocesamiento y la prueba de hip√≥tesis.\n",
    "\n",
    "Siempre que investiguemos, necesitamos formular hip√≥tesis que despu√©s podamos probar. A veces, aceptaremos estas hip√≥tesis; otras veces, las rechazaremos. Para tomar las decisiones adecuadas, una empresa debe ser capaz de entender si est√° haciendo las suposiciones correctas.\n",
    "\n",
    "En este proyecto, comparar√°s las preferencias musicales de las ciudades de Springfield y Shelbyville. Estudiar√°s datos reales de m√∫sica online para probar la hip√≥tesis que planteamos a continuaci√≥n y comparar√°s el comportamiento de los usuarios de estas dos ciudades.\n",
    "\n",
    "### Objetivo:\n",
    "Probar la hip√≥tesis:\n",
    "1. La actividad de los usuarios difiere seg√∫n el d√≠a de la semana y dependiendo de la ciudad.\n",
    "\n",
    "\n",
    "### Etapas\n",
    "Los datos del comportamiento de los usuarios se almacenan en el archivo `/datasets/music_project_en.csv`. No hay informaci√≥n sobre la calidad de los datos, as√≠ que necesitar√°s examinarlos antes de probar la hip√≥tesis.\n",
    "\n",
    "Primero, debes evaluar la calidad de los datos y ver si los problemas son significativos. M√°s tarde, durante el preprocesamiento de datos, deber√°s abordar los problemas m√°s cr√≠ticos.\n",
    "\n",
    "Tu proyecto contar√° con estas tres etapas:\n",
    " 1. Descripci√≥n de los datos.\n",
    " 2. Preprocesamiento de los datos.\n",
    " 3. Prueba de la hip√≥tesis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDt6pg-Rw-1U"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "# Etapa 1. Descripci√≥n de los datos <a id='data_review'></a>\n",
    "\n",
    "Abre los datos y exam√≠nalos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57eAOGIz_Zcs"
   },
   "source": [
    "Etapa 1.1. Necesitar√°s `pandas`, as√≠ que imp√≥rtalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "AXN7PHPN_Zcs",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Importa pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG23P8tt_Zcs"
   },
   "source": [
    "Etapa 1.2. Lee el archivo `music_project_en.csv` de la carpeta `/datasets/` y gu√°rdalo en la variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFVu7vqh_Zct",
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# Lee el archivo y almac√©nalo en df\n",
    "df = pd.read_csv('../datasets/music_project_en.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDoOMd3uTqnZ"
   },
   "source": [
    "Etapa 1.3. Muestra las 10 primeras filas de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "oWTVX3gW_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userID                        Track            artist   genre  \\\n",
      "0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n",
      "1  55204538  Delayed Because of Accident  Andreas R√∂nnberg    rock   \n",
      "2    20EC38            Funicul√¨ funicul√†       Mario Lanza     pop   \n",
      "3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n",
      "4  E2DC1FAE                  Soul People        Space Echo   dance   \n",
      "5  842029A1                       Chains          Obladaet  rusrap   \n",
      "6  4CB90AA5                         True      Roman Messer   dance   \n",
      "7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n",
      "8  8FA1D3BE                     L‚Äôestate       Julia Dalia  ruspop   \n",
      "9  E772D5C0                    Pessimist               NaN   dance   \n",
      "\n",
      "        City        time        Day  \n",
      "0  Shelbyville  20:28:33  Wednesday  \n",
      "1  Springfield  14:07:09     Friday  \n",
      "2  Shelbyville  20:58:07  Wednesday  \n",
      "3  Shelbyville  08:37:09     Monday  \n",
      "4  Springfield  08:34:34     Monday  \n",
      "5  Shelbyville  13:09:41     Friday  \n",
      "6  Springfield  13:00:07  Wednesday  \n",
      "7  Springfield  20:47:49  Wednesday  \n",
      "8  Springfield  09:17:40     Friday  \n",
      "9  Shelbyville  21:20:49  Wednesday  \n"
     ]
    }
   ],
   "source": [
    "# Obt√©n las 10 primeras filas de la tabla df\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EO73Kwic_Zct"
   },
   "source": [
    "Etapa 1.4. Obt√©n la informaci√≥n general sobre la tabla con el m√©todo info()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "DSf2kIb-_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65079 entries, 0 to 65078\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0     userID  65079 non-null  object\n",
      " 1   Track     63736 non-null  object\n",
      " 2   artist    57512 non-null  object\n",
      " 3   genre     63881 non-null  object\n",
      " 4     City    65079 non-null  object\n",
      " 5   time      65079 non-null  object\n",
      " 6   Day       65079 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Obt√©n la informaci√≥n general sobre nuestros datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "Estas son nuestras observaciones sobre la tabla. Contiene siete columnas que almacenan los mismos tipos de datos: `object`.\n",
    "\n",
    "Seg√∫n la documentaci√≥n:\n",
    "- `' userID'`: identificador del usuario;\n",
    "- `'Track'`: t√≠tulo de la canci√≥n;\n",
    "- `'artist'`: nombre del artista;\n",
    "- `'genre'`: g√©nero de la canci√≥n;\n",
    "- `'City'`: ciudad del usuario;\n",
    "- `'time'`: la hora exacta en la que se reprodujo la canci√≥n;\n",
    "- `'Day'`: d√≠a de la semana.\n",
    "\n",
    "Podemos ver tres problemas con el estilo en los encabezados de la tabla:\n",
    "1. Algunos encabezados est√°n en may√∫sculas, otros en min√∫sculas.\n",
    "2. Hay espacios en algunos encabezados.\n",
    "3. `Detecta el tercer problema por tu cuenta y descr√≠belo aqu√≠`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB6-dXG_Zct"
   },
   "source": [
    "# Conclusiones.<a id='data_review_conclusions'></a>\n",
    "### Escribe algunas observaciones por tu parte. Contesta a las siguientes preguntas: \n",
    "\n",
    "`1.   ¬øQu√© tipo de datos hay en las filas? ¬øC√≥mo podemos saber qu√© almacenan las columnas?`\n",
    "\n",
    "`2.   ¬øHay suficientes datos para proporcionar respuestas a nuestra hip√≥tesis o necesitamos m√°s informaci√≥n?`\n",
    "\n",
    "`3.   ¬øNotaste alg√∫n problema en los datos, como valores ausentes, duplicados o tipos de datos incorrectos?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emewmQcy3m_F"
   },
   "source": [
    "Escribe aqu√≠ tus respuestas:\n",
    "\n",
    "1. Debo usar df. info() para proporcionar un resumen completo, incluyendo el tipo de atos (dtype) de cada columna. Tambi√©n debo usar df.dtypes() para mostrar una serie de pandas con el tipo de dato para cada columna. Para saber que almacenan las columnas, debo usar df.head()  df.describe()  df.columns() df['un_nombre_de_columna'].unique()  df['un_nombre_de_columna'].value_counts()\n",
    "\n",
    "2. No. Algunos nombres o encabezados estan en mayusculas y en minusculas, tambien algunos contienen espacios en blanco al principio y al final de los nombres.\n",
    "\n",
    "3. Los espacios en blanco al final y al comienzo de algunos de los nombres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eL__vcwViOi"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "# Etapa 2. Preprocesamiento de los datos <a id='data_preprocessing'></a>\n",
    "\n",
    "Tu objetivo aqu√≠ es preparar los datos para analizarlos.\n",
    "El primer paso es resolver los problemas con los encabezados. Despu√©s podemos avanzar a los valores ausentes y duplicados. ¬°Empecemos!\n",
    "\n",
    "Vamos a corregir el formato en los encabezados de la tabla.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "# Estilo del encabezado <a id='header_style'></a>\n",
    "\n",
    "Etapa 2.1. Muestra los encabezados de la tabla (los nombres de las columnas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "oKOTdF_Q_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra los nombres de las columnas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Un4tf8yr-GN2",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n",
      "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "# Limpia los nombres de las columnas y tambien va eliminando los espacios en blanco al principio y al final\n",
    "#conviertiendo todos los caracteres en columnas.\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Muestra Los nombres de las columnas para verificar el cambio\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj5534cv_Zct"
   },
   "source": [
    "Vamos cambiar los encabezados de la tabla siguiendo las reglas estil√≠sticas convencionales:\n",
    "*   Todos los caracteres deben ser min√∫sculas.\n",
    "*   Elimina los espacios.\n",
    "*   Si el nombre tiene varias palabras, utiliza snake_case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xu0zkfe5zNJe"
   },
   "source": [
    "Anteriormente, aprendiste una forma autom√°tica de cambiar el nombre de las columnas. Vamos a aplicarla ahora.\n",
    "\n",
    "Etapa 2.2. Utiliza el bucle for para iterar sobre los nombres de las columnas y poner todos los caracteres en min√∫sculas. Cuando hayas terminado, vuelve a mostrar los encabezados de la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "6I_RwwMhzM4e",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userid                        track            artist  genre  \\\n",
      "0  FFB692EC            Kamigata To Boots  The Mass Missile   rock   \n",
      "1  55204538  Delayed Because of Accident  Andreas R√∂nnberg   rock   \n",
      "2    20EC38            Funicul√¨ funicul√†       Mario Lanza    pop   \n",
      "3  A3DD03C9        Dragons in the Sunset        Fire + Ice   folk   \n",
      "4  E2DC1FAE                  Soul People        Space Echo  dance   \n",
      "\n",
      "          city      time        day  \n",
      "0  Shelbyville  20:28:33  Wednesday  \n",
      "1  Springfield  14:07:09     Friday  \n",
      "2  Shelbyville  20:58:07  Wednesday  \n",
      "3  Shelbyville  08:37:09     Monday  \n",
      "4  Springfield  08:34:34     Monday  \n"
     ]
    }
   ],
   "source": [
    "# Bucle en los encabezados que lo pone todo en min√∫sculas\n",
    "nuevas_columnas = []\n",
    "for columna in df.columns:\n",
    "    nuevas_columnas.append(columna.lower())\n",
    "\n",
    "df.columns = nuevas_columnas\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pweIRxjSzPYW"
   },
   "source": [
    "Etapa 2.3. Ahora, utilizando el mismo m√©todo, elimina los espacios al principio y al final de los nombres de las columnas y muestra los nombres de las columnas de nuevo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "vVQXbFyJzSYl",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Bucle en los encabezados que elimina los espacios\n",
    "nuevas_columnas = []\n",
    "for columna in df.columns:\n",
    "    nuevas_columnas.append(columna.strip())\n",
    "\n",
    "df.columns = nuevas_columnas\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCb8MW1JzURd"
   },
   "source": [
    "Etapa 2.4. Necesitamos aplicar la regla de snake_case en la columna `userid`. Debe ser `user_id`. Cambia el nombre de esta columna y muestra los nombres de todas las columnas cuando hayas terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ISlFqs5y_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cambia el nombre de la columna \"userid\"\n",
    "df = df.rename(columns={'userid': 'user_id'})\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dqbh00J_Zct"
   },
   "source": [
    "Etapa 2.5. Comprueba el resultado. Muestra los encabezados una vez m√°s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "d4NOAmTW_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id                        track            artist  genre  \\\n",
      "0  FFB692EC            Kamigata To Boots  The Mass Missile   rock   \n",
      "1  55204538  Delayed Because of Accident  Andreas R√∂nnberg   rock   \n",
      "2    20EC38            Funicul√¨ funicul√†       Mario Lanza    pop   \n",
      "3  A3DD03C9        Dragons in the Sunset        Fire + Ice   folk   \n",
      "4  E2DC1FAE                  Soul People        Space Echo  dance   \n",
      "\n",
      "          city      time        day  \n",
      "0  Shelbyville  20:28:33  Wednesday  \n",
      "1  Springfield  14:07:09     Friday  \n",
      "2  Shelbyville  20:58:07  Wednesday  \n",
      "3  Shelbyville  08:37:09     Monday  \n",
      "4  Springfield  08:34:34     Monday  \n"
     ]
    }
   ],
   "source": [
    "# Comprueba el resultado: lista de encabezados\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYJk6ksJVpOl"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "# Valores ausentes <a id='missing_values'></a>\n",
    " Etapa 2.5. Primero, encuentra el n√∫mero de valores ausentes en la tabla. Debes utilizar dos m√©todos para obtener el n√∫mero de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "RskX29qr_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de valores ausentes por columna es (m√©todo isnull().sum()):\n",
      "user_id       0\n",
      "track      1343\n",
      "artist     7567\n",
      "genre      1198\n",
      "city          0\n",
      "time          0\n",
      "day           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calcula el n√∫mero de valores ausentes\n",
    "valores_ausentes_por_columna = df.isnull().sum()\n",
    "print(\"El n√∫mero de valores ausentes por columna es (m√©todo isnull().sum()):\")\n",
    "print(valores_ausentes_por_columna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qubhgnlO_Zct"
   },
   "source": [
    "No todos los valores ausentes afectan de la misma forma a la investigaci√≥n. Por ejemplo, los valores ausentes en 'track' y 'artist' no son cruciales para el an√°lisis, ya que estos datos son m√°s descriptivos que anal√≠ticos. Por eso, puedes reemplazarlos directamente con un valor predeterminado como el string 'unknown' (desconocido)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzJd_997466T"
   },
   "source": [
    "En cambio, los valores ausentes en 'genre' s√≠ pueden influir en la comparaci√≥n entre las preferencias musicales de Springfield y Shelbyville. En un escenario real, lo ideal ser√≠a investigar por qu√© faltan estos datos e intentar recuperarlos. Pero en este proyecto no tenemos esa posibilidad, as√≠ que deber√°s rellenar esos valores con un valor predeterminado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IzUHGWE5Els"
   },
   "source": [
    "Como vimos anteriormente en las lecciones, la mejor manera de hacerlo es crear una lista con los nombres de las columnas que necesitan reemplazarse.  Luego, utilizar esta lista para iterar sobre cada columna y realizar el reemplazo correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSv2laPA_Zct"
   },
   "source": [
    "Etapa 2.6. Sustituye los valores ausentes en las columnas `'track'`, `'artist'` y `'genre'` con el string `'unknown'`.\n",
    "\n",
    "1. Crea una lista llamada columns_to_replace que contenga los nombres de las columnas 'track', 'artist' y 'genre'.\n",
    "\n",
    "2. Usa un bucle for para iterar sobre cada columna en columns_to_replace.\n",
    "\n",
    "3. Dentro del bucle, sustituye los valores ausentes en cada columna con el string `'unknown'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "KplB5qWs_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de los valores ausentes despu√©s de la sustituci√≥n es:\n",
      "track     0\n",
      "artist    0\n",
      "genre     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Bucle en los encabezados reemplazando los valores ausentes con 'unknown'\n",
    "columns_to_replace = ['track', 'artist', 'genre']\n",
    "\n",
    "for columna in columns_to_replace:\n",
    "    df[columna] = df[columna].fillna('unknown')\n",
    "\n",
    "print(\"El n√∫mero de los valores ausentes despu√©s de la sustituci√≥n es:\")\n",
    "print(df[['track', 'artist', 'genre']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilsm-MZo_Zct"
   },
   "source": [
    "Etapa 2.7. Ahora comprueba el resultado para asegurarte de que no falten valores ausentes por reemplazar en el conjunto de datos. Para ello, cuenta los valores ausentes una vez m√°s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "Tq4nYRX4_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de los valores ausentes en todo el dataframe despu√©s de la sustituci√≥n es:\n",
      "user_id    0\n",
      "track      0\n",
      "artist     0\n",
      "genre      0\n",
      "city       0\n",
      "time       0\n",
      "day        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cuenta los valores ausentes\n",
    "print(\"El n√∫mero de los valores ausentes en todo el dataframe despu√©s de la sustituci√≥n es:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ZIBmq9VrsK"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "# Duplicados <a id='duplicates'></a>\n",
    "\n",
    "Etapa 2.8. Encuentra el n√∫mero de duplicados expl√≠citos en la tabla. Una vez m√°s, debes aplicar dos m√©todos para obtener la cantidad de duplicados expl√≠citos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "36eES_S0_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de datos duplicados expl√≠citos es (m√©todo duplicated().sum()): 3826\n"
     ]
    }
   ],
   "source": [
    "# Cuenta los duplicados expl√≠citos\n",
    "numero_duplicados = df.duplicated().sum()\n",
    "print(f\"El n√∫mero de datos duplicados expl√≠citos es (m√©todo duplicated().sum()): {numero_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot25h6XR_Zct"
   },
   "source": [
    "Etapa 2.9. Ahora, elimina todos los duplicados. Para ello, llama al m√©todo que hace exactamente esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "exFHq6tt_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de filas en el dataframe despu√©s de eliminar los datos duplicados: 61253\n"
     ]
    }
   ],
   "source": [
    "# Elimina los duplicados expl√≠citos\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"El n√∫mero de filas en el dataframe despu√©s de eliminar los datos duplicados: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im2YwBEG_Zct"
   },
   "source": [
    "Etapa 2.10. Comprobemos ahora si conseguimos eliminar todos los duplicados. Cuenta los duplicados expl√≠citos una vez m√°s para asegurarte de haberlos eliminado todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "-8PuNWQ0_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de datos duplicados expl√≠citos despu√©s de eliminar es: 0\n"
     ]
    }
   ],
   "source": [
    "# Comprueba de nuevo si hay duplicados\n",
    "numero_duplicados_despues = df.duplicated().sum()\n",
    "print(f\"El n√∫mero de datos duplicados expl√≠citos despu√©s de eliminar es: {numero_duplicados_despues}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFBsxAr_Zct"
   },
   "source": [
    "Ahora queremos deshacernos de los duplicados impl√≠citos en la columna `genre`. Por ejemplo, el nombre de un g√©nero se puede escribir de varias formas. Dichos errores tambi√©n pueden afectar al resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSjWwsOh_Zct"
   },
   "source": [
    "Etapa 2.11. Primero debemos mostrar una lista de nombres de g√©neros √∫nicos, por orden alfab√©tico. Para ello:\n",
    "1. Extrae la columna `genre` del DataFrame.\n",
    "2. Llama al m√©todo que devolver√° todos los valores √∫nicos en la columna extra√≠da.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "JIUcqzZN_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La lista de g√©neros √∫nicos en orden alfab√©tico:\n",
      "acid\n",
      "acoustic\n",
      "action\n",
      "adult\n",
      "africa\n",
      "afrikaans\n",
      "alternative\n",
      "ambient\n",
      "americana\n",
      "animated\n",
      "anime\n",
      "arabesk\n",
      "arabic\n",
      "arena\n",
      "argentinetango\n",
      "art\n",
      "audiobook\n",
      "avantgarde\n",
      "ax√©\n",
      "baile\n",
      "balkan\n",
      "beats\n",
      "bigroom\n",
      "black\n",
      "bluegrass\n",
      "blues\n",
      "bollywood\n",
      "bossa\n",
      "brazilian\n",
      "breakbeat\n",
      "breaks\n",
      "broadway\n",
      "cantautori\n",
      "cantopop\n",
      "canzone\n",
      "caribbean\n",
      "caucasian\n",
      "celtic\n",
      "chamber\n",
      "children\n",
      "chill\n",
      "chinese\n",
      "choral\n",
      "christian\n",
      "christmas\n",
      "classical\n",
      "classicmetal\n",
      "club\n",
      "colombian\n",
      "comedy\n",
      "conjazz\n",
      "contemporary\n",
      "country\n",
      "cuban\n",
      "dance\n",
      "dancehall\n",
      "dancepop\n",
      "dark\n",
      "death\n",
      "deep\n",
      "deutschrock\n",
      "deutschspr\n",
      "dirty\n",
      "disco\n",
      "dnb\n",
      "documentary\n",
      "downbeat\n",
      "downtempo\n",
      "drum\n",
      "dub\n",
      "dubstep\n",
      "eastern\n",
      "easy\n",
      "electronic\n",
      "electropop\n",
      "emo\n",
      "entehno\n",
      "epicmetal\n",
      "estrada\n",
      "ethnic\n",
      "eurofolk\n",
      "european\n",
      "experimental\n",
      "extrememetal\n",
      "fado\n",
      "film\n",
      "fitness\n",
      "flamenco\n",
      "folk\n",
      "folklore\n",
      "folkmetal\n",
      "folkrock\n",
      "folktronica\n",
      "forr√≥\n",
      "frankreich\n",
      "franz√∂sisch\n",
      "french\n",
      "funk\n",
      "future\n",
      "gangsta\n",
      "garage\n",
      "german\n",
      "ghazal\n",
      "gitarre\n",
      "glitch\n",
      "gospel\n",
      "gothic\n",
      "grime\n",
      "grunge\n",
      "gypsy\n",
      "handsup\n",
      "hard'n'heavy\n",
      "hardcore\n",
      "hardstyle\n",
      "hardtechno\n",
      "hip\n",
      "hip-hop\n",
      "hiphop\n",
      "historisch\n",
      "holiday\n",
      "hop\n",
      "horror\n",
      "house\n",
      "idm\n",
      "independent\n",
      "indian\n",
      "indie\n",
      "indipop\n",
      "industrial\n",
      "inspirational\n",
      "instrumental\n",
      "international\n",
      "irish\n",
      "jam\n",
      "japanese\n",
      "jazz\n",
      "jewish\n",
      "jpop\n",
      "jungle\n",
      "k-pop\n",
      "karadeniz\n",
      "karaoke\n",
      "kayokyoku\n",
      "korean\n",
      "laiko\n",
      "latin\n",
      "latino\n",
      "leftfield\n",
      "local\n",
      "lounge\n",
      "loungeelectronic\n",
      "lovers\n",
      "malaysian\n",
      "mandopop\n",
      "marschmusik\n",
      "meditative\n",
      "mediterranean\n",
      "melodic\n",
      "metal\n",
      "metalcore\n",
      "mexican\n",
      "middle\n",
      "minimal\n",
      "miscellaneous\n",
      "modern\n",
      "mood\n",
      "mpb\n",
      "muslim\n",
      "native\n",
      "neoklassik\n",
      "neue\n",
      "new\n",
      "newage\n",
      "newwave\n",
      "nu\n",
      "nujazz\n",
      "numetal\n",
      "oceania\n",
      "old\n",
      "opera\n",
      "orchestral\n",
      "other\n",
      "piano\n",
      "pop\n",
      "popelectronic\n",
      "popeurodance\n",
      "post\n",
      "posthardcore\n",
      "postrock\n",
      "power\n",
      "progmetal\n",
      "progressive\n",
      "psychedelic\n",
      "punjabi\n",
      "punk\n",
      "quebecois\n",
      "ragga\n",
      "ram\n",
      "rancheras\n",
      "rap\n",
      "rave\n",
      "reggae\n",
      "reggaeton\n",
      "regional\n",
      "relax\n",
      "religious\n",
      "retro\n",
      "rhythm\n",
      "rnb\n",
      "rnr\n",
      "rock\n",
      "rockabilly\n",
      "romance\n",
      "roots\n",
      "ruspop\n",
      "rusrap\n",
      "rusrock\n",
      "salsa\n",
      "samba\n",
      "schlager\n",
      "self\n",
      "sertanejo\n",
      "shoegazing\n",
      "showtunes\n",
      "singer\n",
      "ska\n",
      "slow\n",
      "smooth\n",
      "soul\n",
      "soulful\n",
      "sound\n",
      "soundtrack\n",
      "southern\n",
      "specialty\n",
      "speech\n",
      "spiritual\n",
      "sport\n",
      "stonerrock\n",
      "surf\n",
      "swing\n",
      "synthpop\n",
      "s√§ngerportrait\n",
      "tango\n",
      "tanzorchester\n",
      "taraftar\n",
      "tech\n",
      "techno\n",
      "thrash\n",
      "top\n",
      "traditional\n",
      "tradjazz\n",
      "trance\n",
      "tribal\n",
      "trip\n",
      "triphop\n",
      "tropical\n",
      "t√ºrk\n",
      "t√ºrk√ße\n",
      "unknown\n",
      "urban\n",
      "uzbek\n",
      "vari√©t√©\n",
      "vi\n",
      "videogame\n",
      "vocal\n",
      "western\n",
      "world\n",
      "worldbeat\n",
      "√Ø√Æ√Ø\n"
     ]
    }
   ],
   "source": [
    "# Inspecciona los nombres de g√©neros √∫nicos\n",
    "\n",
    "# Primero extraigo la columna 'genre'\n",
    "generos = df['genre']\n",
    "\n",
    "# Despu√©s obtengo los valores √∫nicos\n",
    "generos_unicos = generos.unique()\n",
    "\n",
    "# Ahora debo ordenar alfab√©ticamente la lista de g√©neros √∫nicos\n",
    "generos_unicos_ordenados = sorted(generos_unicos)\n",
    "\n",
    "# Por √∫ltimo muestro la lista ordenada\n",
    "print(\"La lista de g√©neros √∫nicos en orden alfab√©tico:\")\n",
    "for genero in generos_unicos_ordenados:\n",
    "    print(genero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Vamos a examinar la lista para identificar **duplicados impl√≠citos** del g√©nero `hiphop`, es decir, nombres mal escritos o variantes que hacen referencia al mismo g√©nero musical.\n",
    "\n",
    "Algunos de los duplicados que encontrar√°s son:\n",
    "\n",
    "* `hip`  \n",
    "* `hop`  \n",
    "* `hip-hop`  \n",
    "\n",
    "Para solucionarlo, vamos a crear una funci√≥n llamada `replace_wrong_genres()` que tendr√° dos par√°metros:\n",
    "\n",
    "* `wrong_genres`: una lista con todos los valores que deben ser reemplazados.  \n",
    "* `correct_genre`: un string que se utilizar√° como valor de reemplazo.\n",
    "\n",
    "El objetivo de esta funci√≥n es **corregir los valores en la columna `'genre'` del DataFrame `df`**, reemplazando cada valor de la lista `wrong_genres` por `correct_genre`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kmujhjP_bIl"
   },
   "source": [
    "Etapa 2.12.\n",
    "1. Define una funci√≥n llamada `replace_wrong_genres()` que reciba dos par√°metros: `wrong_genres` y `correct_genre`.\n",
    "\n",
    "2. Dentro de la funci√≥n, utiliza un bucle `for` para iterar sobre cada valor en la lista `wrong_genres`.\n",
    "\n",
    "3. En cada iteraci√≥n, accede a la columna `'genre'` del DataFrame `df` y utiliza el m√©todo `.replace()` para sustituir el valor incorrecto por `correct_genre`.\n",
    "\n",
    "4. Llama a la funci√≥n y pasa como argumentos:\n",
    "   - Una lista con los duplicados impl√≠citos: `['hip', 'hop', 'hip-hop']`\n",
    "   - El string de reemplazo: `'hiphop'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "ErNDkmns_Zct",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos de la columna 'genre' despu√©s del reemplazo:\n",
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n",
      " 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n",
      " 'rusrock' 'dnb' 't√ºrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'drum' 'extrememetal' 't√ºrk√ße' 'experimental' 'easy'\n",
      " 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n",
      " 'stonerrock' 'industrial' 'funk' 'middle' 'vari√©t√©' 'other' 'adult'\n",
      " 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n",
      " 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n",
      " 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n",
      " 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n",
      " 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n",
      " 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n",
      " 'africa' 'audiobook' 'jewish' 's√§ngerportrait' 'deutschrock' 'eastern'\n",
      " 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n",
      " 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n",
      " 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n",
      " 'brazilian' '√Ø√Æ√Ø' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n",
      " 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n",
      " 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n",
      " 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n",
      " 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n",
      " 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'franz√∂sisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'ax√©' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr√≥' 'dirty'\n",
      " 'regional']\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n para reemplazar los duplicados impl√≠citos\n",
    "def replace_wrong_genres(wrong_genres, correct_genre):\n",
    "    \"\"\"\n",
    "    Reemplaza una lista de g√©neros incorrectos con un g√©nero correcto en la columna 'genre' del dataframe df.\n",
    "\n",
    "    Args:\n",
    "        wrong_genres (list): Una lista de strings que representan los nombres de g√©nero incorrectos.\n",
    "        correct_genre (str): El string que representa el nombre de g√©nero correcto con el que se reemplazar√°n los incorrectos.\n",
    "    \"\"\"\n",
    "    for wrong_genre in wrong_genres:\n",
    "        df['genre'] = df['genre'].replace(wrong_genre, correct_genre)\n",
    "\n",
    "# Definimos la lista de g√©neros incorrectos y el g√©nero correcto\n",
    "wrong_genres_list = ['hip', 'hop', 'hip-hop']\n",
    "correct_genre_name = 'hiphop'\n",
    "\n",
    "# Llamamos a la funci√≥n para realizar el reemplazo\n",
    "replace_wrong_genres(wrong_genres_list, correct_genre_name)\n",
    "\n",
    "# Vamos a verificar los cambios mostrando algunos valores √∫nicos de la columna 'genre'\n",
    "print(\"Valores √∫nicos de la columna 'genre' despu√©s del reemplazo:\")\n",
    "print(df['genre'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoBJxbA_Zct"
   },
   "source": [
    "Etapa 2.13. Ahora, llama a `replace_wrong_genres()` y p√°sale estos argumentos para que retire los duplicados impl√≠citos (`hip`, `hop` y `hip-hop`) y los sustituya por `hiphop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "YN5i2hpmSo09",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores √∫nicos de la columna 'genre' despu√©s del reemplazo:\n",
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n",
      " 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n",
      " 'rusrock' 'dnb' 't√ºrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'drum' 'extrememetal' 't√ºrk√ße' 'experimental' 'easy'\n",
      " 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n",
      " 'stonerrock' 'industrial' 'funk' 'middle' 'vari√©t√©' 'other' 'adult'\n",
      " 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n",
      " 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n",
      " 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n",
      " 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n",
      " 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n",
      " 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n",
      " 'africa' 'audiobook' 'jewish' 's√§ngerportrait' 'deutschrock' 'eastern'\n",
      " 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n",
      " 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n",
      " 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n",
      " 'brazilian' '√Ø√Æ√Ø' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n",
      " 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n",
      " 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n",
      " 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n",
      " 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n",
      " 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'franz√∂sisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'ax√©' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr√≥' 'dirty'\n",
      " 'regional']\n"
     ]
    }
   ],
   "source": [
    "# Elimina los duplicados impl√≠citos\n",
    "\n",
    "def replace_wrong_genres(wrong_genres, correct_genre):\n",
    "    \"\"\"\n",
    "    Reemplaza una lista de g√©neros incorrectos con un g√©nero correcto en la columna 'genre' del DataFrame df.\n",
    "\n",
    "    Args:\n",
    "        wrong_genres (list): Una lista de strings que representan los nombres de g√©nero incorrectos.\n",
    "        correct_genre (str): El string que representa el nombre de g√©nero correcto con el que se reemplazar√°n los incorrectos.\n",
    "    \"\"\"\n",
    "    for wrong_genre in wrong_genres:\n",
    "        df['genre'] = df['genre'].replace(wrong_genre, correct_genre)\n",
    "\n",
    "# Definimos la lista de g√©neros incorrectos y el g√©nero correcto\n",
    "wrong_genres_list = ['hip', 'hop', 'hip-hop']\n",
    "correct_genre_name = 'hiphop'\n",
    "\n",
    "# Llamamos a la funci√≥n para realizar el reemplazo\n",
    "replace_wrong_genres(wrong_genres_list, correct_genre_name)\n",
    "\n",
    "# Vamos a verificar los cambios mostrando algunos valores √∫nicos de la columna 'genre'\n",
    "print(\"Valores √∫nicos de la columna 'genre' despu√©s del reemplazo:\")\n",
    "print(df['genre'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQKF16_RG15m"
   },
   "source": [
    "Etapa 2.14. Aseg√∫rate de que los nombres duplicados se hayan eliminado. Muestra la lista de valores √∫nicos de la columna `'genre'` una vez m√°s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "wvixALnFG15m",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de valores √∫nicos de la columna 'genre' despu√©s del reemplazo:\n",
      "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n",
      " 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n",
      " 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n",
      " 'rusrock' 'dnb' 't√ºrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n",
      " 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n",
      " 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n",
      " 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n",
      " 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n",
      " 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n",
      " 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n",
      " 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n",
      " 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n",
      " 'disco' 'religious' 'drum' 'extrememetal' 't√ºrk√ße' 'experimental' 'easy'\n",
      " 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n",
      " 'stonerrock' 'industrial' 'funk' 'middle' 'vari√©t√©' 'other' 'adult'\n",
      " 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n",
      " 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n",
      " 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n",
      " 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n",
      " 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n",
      " 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n",
      " 'africa' 'audiobook' 'jewish' 's√§ngerportrait' 'deutschrock' 'eastern'\n",
      " 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n",
      " 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n",
      " 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n",
      " 'brazilian' '√Ø√Æ√Ø' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n",
      " 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n",
      " 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n",
      " 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n",
      " 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n",
      " 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n",
      " 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n",
      " 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n",
      " 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n",
      " 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n",
      " 'synthpop' 'rave' 'franz√∂sisch' 'quebecois' 'speech' 'soulful' 'jam'\n",
      " 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n",
      " 'ax√©' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr√≥' 'dirty'\n",
      " 'regional']\n"
     ]
    }
   ],
   "source": [
    "# Comprueba de nuevo los duplicados impl√≠citos\n",
    "print(\"Lista de valores √∫nicos de la columna 'genre' despu√©s del reemplazo:\")\n",
    "print(df['genre'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALgNbvF3VtPA"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "# Conclusiones <a id='data_preprocessing_conclusions'></a>\n",
    "\n",
    "`Redacta un breve resumen de lo que descubriste al analizar los datos. Tu respuesta debe identificar los problemas detectados, explicar c√≥mo los resolviste y describir c√≥mo esas acciones mejoran la calidad del an√°lisis.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN8zFHxhAF5O"
   },
   "source": [
    "Etapa 2.14. Descr√≠belo aqu√≠.\n",
    "Problemas Detectados:\n",
    "Durante la inspecci√≥n inicial del conjunto de datos, identifiqu√© los siguientes problemas que pueden afectar la calidad de un an√°lisis:\n",
    "1.\tLos nombres de las columnas eran inconsistentes. Conten√≠an letras may√∫sculas, espacios al principio y al final, y utilizaban un formato inconsistente, todo esto dificulta la referencia y el procesamiento uniforme de las columnas.\n",
    "2.\tLos valores ausentes. Los valores faltantes en algunas columnas, este error com√∫n puede sesgar los an√°lisis y generar errores si no se gestionan adecuadamente.\n",
    "3.\tLos duplicados expl√≠citos. Se identifican filas que son duplicados exactos de otras filas. Estos duplicados no aportan informaci√≥n adicional y pueden inflar los conteos y afectar las estad√≠sticas.\n",
    "4.\tDuplicados impl√≠citos en la columna 'genre'. Los diferentes nombres para el mismo g√©nero musical, como 'hip', 'hop' y 'hip-hop', que en realidad deben agruparse con el mismo nombre de: ('hiphop'). Esta inconsistencia dificulta el an√°lisis por g√©nero.\n",
    "Resoluci√≥n de problemas:\n",
    "Para normalizar los nombres de las columnas, debo iterar sobre los nombres, convertirlos a min√∫sculas y eliminar los espacios en blanco al principio y al final. Luego, aplicar la convenci√≥n snake_case para el nombre de la columna 'userid', cambi√°ndolo a 'user_id'. Estas correcciones crearon un esquema de nombres de columnas m√°s consistente y f√°cil de usar.\n",
    "\n",
    "La Imputaci√≥n de valores ausentes, reemplazar los valores ausentes encontrados en las columnas 'track', 'artist' y 'genre' con la cadena 'unknown'.\n",
    "Si bien esta es una estrategia simple, asegura que estos campos tengan un valor y puedan incluirse en an√°lisis posteriores sin generar errores.\n",
    "\n",
    "Eliminar los duplicados expl√≠citos: Utiliz√© el m√©todo drop_duplicates() para eliminar todas las filas que eran duplicados exactos. Esto asegur√≥ que cada fila en el conjunto de datos represente una entrada √∫nica.\n",
    "\n",
    "Correcci√≥n de duplicados impl√≠citos en 'genre',  definir una funci√≥n: replace_wrong_genres() que tom√≥ una lista de representaciones incorrectas del g√©nero hip-hop ('hip', 'hop', 'hip-hop') y las reemplaz√≥ por la forma correcta ('hiphop') en la columna 'genre'. Esto homogeneiz√≥ la representaci√≥n de este g√©nero.\n",
    "\n",
    "Para mejorar estas acciones y generar un mejor an√°lisis:\n",
    "La consistencia y facilidad de uso implica normalizar los nombres de las columnas para que el c√≥digo sea m√°s legible, menos propenso a errores y facilitar el acceso a las columnas para futuros an√°lisis.\n",
    "La integridad de los datos implica tratar los valores ausentes y asegurar que los an√°lisis no se vean afectados por la falta de informaci√≥n en estas columnas.\n",
    "\n",
    "Tambi√©n la precisi√≥n de los conteos y estad√≠sticas, eliminar los duplicados expl√≠citos garantiza que los conteos y las estad√≠sticas descriptivas reflejen mejor la cantidad real de datos √∫nicos, evitando la sobreestimaci√≥n. As√≠ como tambi√©n la correcci√≥n de los duplicados impl√≠citos en la columna 'genre' permite realizar an√°lisis m√°s precisos y significativos basados en los g√©neros musicales, ya que las diferentes representaciones del mismo g√©nero ahora se agrupan correctamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK1es74rVujj"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "# Etapa 3. Prueba de la hip√≥tesis <a id='hypothesis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "La hip√≥tesis que queremos probar plantea que existen diferencias en la forma en que los usuarios de Springfield y Shelbyville consumen m√∫sica.\n",
    "Para analizar esto, nos enfocaremos en los datos correspondientes a tres d√≠as espec√≠ficos de la semana: lunes, mi√©rcoles y viernes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Dw_YMmT_Zcu"
   },
   "source": [
    "El an√°lisis consistir√° en comparar la cantidad de canciones reproducidas por los usuarios de cada ciudad en esos d√≠as. Esto nos permitir√° observar posibles patrones o diferencias en los h√°bitos de consumo entre Springfield y Shelbyville.\n",
    "\n",
    "Para llevar a cabo este an√°lisis, es importante seguir el enfoque de dividir-aplicar-combinar, del que ya hablamos en la lecci√≥n. En este caso:\n",
    "\n",
    "*  Dividir: separamos los datos en grupos seg√∫n la ciudad.\n",
    "\n",
    "*  Aplicar: dentro de cada grupo, contamos cu√°ntas canciones se reprodujeron.\n",
    "\n",
    "*  Combinar: reunimos los resultados en una estructura que nos permita comparar f√°cilmente ambas ciudades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0MoTnZcB-hW"
   },
   "source": [
    "Este procedimiento debe repetirse de forma independiente para cada uno de los tres d√≠as seleccionados. El resultado final debe mostrar el n√∫mero de reproducciones por ciudad en cada uno de esos d√≠as.\n",
    "\n",
    "Una posible forma de estructurar el c√≥digo ser√≠a con la siguiente expresi√≥n:\n",
    "\n",
    "`df.groupby(by='...')['...'].method()`\n",
    "\n",
    "Deber√°s completar los argumentos correspondientes para agrupar por ciudad y contar las canciones reproducidas. Este enfoque te dar√° una visi√≥n clara y comparativa del comportamiento de los usuarios en ambas ciudades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgMGeLF2CMJv"
   },
   "source": [
    "# Tarea. Comparar el comportamiento de los usuarios en las dos ciudades <a id='activity'></a>\n",
    "Etapa 3.1. Cuenta cu√°ntas canciones se reprodujeron en cada ciudad utilizando la columna 'track' como referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "0_Qs96oh_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de canciones reproducidas por cada ciudad:\n",
      "city\n",
      "Shelbyville    18512\n",
      "Springfield    42741\n",
      "Name: track, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Limpia los nombres de las columnas y tambien va eliminando los espacios en blanco al principio y al final\n",
    "#conviertiendo todos los caracteres en columnas.\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Muestra Los nombres de las columnas para verificar el cambio\n",
    "#print(df.columns)\n",
    "\n",
    "# Cuenta las canciones reproducidas en cada ciudad\n",
    "canciones_por_ciudad = df.groupby(by='city')['track'].count()\n",
    "print(\"N√∫mero de canciones reproducidas por cada ciudad:\")\n",
    "print(canciones_por_ciudad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC2tNrlL_Zcu"
   },
   "source": [
    "`Redacta brevemente tus observaciones sobre los resultados. ¬øQu√© diferencias notaste entre Springfield y Shelbyville? ¬øA qu√© podr√≠an deberse esas diferencias?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kjb4vX38DC3I"
   },
   "source": [
    "Etapa 3.2. Escribe tus observaciones aqu√≠.\n",
    "\n",
    "El tama√±o de la poblaci√≥n en cada Ciudad es diferente, el uso de la plataforma, los h√°bitos de escucha, el factor socioecon√≥mico, promociones de eventos locales, publicidad y marketing‚Ä¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Etapa 3.3.\n",
    "1. Agrupa los datos por d√≠a de la semana y cuenta cu√°ntas canciones se reprodujeron los lunes, mi√©rcoles y viernes.\n",
    "\n",
    "2. Utiliza el mismo m√©todo de conteo que antes, pero ahora cambia la columna de agrupaci√≥n para enfocarte en el d√≠a.\n",
    "\n",
    "3. Esto te permitir√° identificar posibles patrones de escucha seg√∫n el d√≠a de la semana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "uZMKjiJz_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de canciones reproducidas al d√≠a:\n",
      "day\n",
      "Friday       21840\n",
      "Monday       21354\n",
      "Wednesday    18059\n",
      "Name: track, dtype: int64\n",
      "N√∫mero de canciones reproducidas por ciudad y d√≠a:\n",
      "city         day      \n",
      "Shelbyville  Friday        5895\n",
      "             Monday        5614\n",
      "             Wednesday     7003\n",
      "Springfield  Friday       15945\n",
      "             Monday       15740\n",
      "             Wednesday    11056\n",
      "Name: track, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calcula las canciones reproducidas en cada uno de los tres d√≠as\n",
    "canciones_por_dia = df.groupby(by='day')['track'].count()\n",
    "print(\"N√∫mero de canciones reproducidas al d√≠a:\")\n",
    "print(canciones_por_dia)\n",
    "\n",
    "# Calcula las canciones reproducidas en cada uno de los tres d√≠as y en cada Ciudad.\n",
    "canciones_por_ciudad_dia = df.groupby(by=['city', 'day'])['track'].count()\n",
    "print(\"N√∫mero de canciones reproducidas por ciudad y d√≠a:\")\n",
    "print(canciones_por_ciudad_dia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_Qx-3NewAnK"
   },
   "source": [
    "`Describe brevemente qu√© observaste al comparar los lunes, mi√©rcoles y viernes. ¬øHubo alg√∫n d√≠a con menos actividad? ¬øCambian las conclusiones si analizas cada ciudad por separado?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q537Zl8oDNfH"
   },
   "source": [
    "Etapa 3.4. Escribe tus observaciones aqu√≠.\n",
    "Hay una variaci√≥n notable en el n√∫mero total de reproducciones y esto se debe al n√∫mero total de la poblaci√≥n en cada Ciudad.\n",
    "Podr√≠a haber una tendencia gradual o una disminuci√≥n en el n√∫mero de reproducciones a lo largo de la semana.\n",
    "\n",
    "Es posible que alguno de los 3 d√≠as, tenga un n√∫mero menor de reproducciones.\n",
    "\n",
    "Un d√≠a podr√≠a ser el de menor actividad en Springfield, pero el de mayor actividad en Shelbyville, o viceversa.\n",
    "\n",
    "Los factores locales como eventos sociales, d√≠as festivos y patrones de trabajo o transporte podr√≠an influir de manera diferente en los h√°bitos de escuchar m√∫sica en cada ciudad en diferentes d√≠as de la semana.\n",
    "\n",
    "Siendo el n√∫mero de usuarios bastante distinto en cada Ciudad; podr√≠a existir un patr√≥n especifico de escuchar m√∫sica; que estar√≠a dominando la Ciudad con mayor n√∫mero de usuarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "Hasta ahora has aprendido a contar entradas agrup√°ndolas por un solo criterio, como la ciudad o el d√≠a de la semana. Ahora vamos a dar un paso m√°s: necesitas crear una funci√≥n que **cuente cu√°ntas canciones se reprodujeron en una ciudad espec√≠fica durante un d√≠a determinado**, combinando ambos criterios de filtrado.\n",
    "\n",
    "La funci√≥n se llamar√° `number_tracks()` y debe aceptar dos par√°metros:\n",
    "\n",
    "- `day`: un d√≠a de la semana (por ejemplo, `'Monday'`).\n",
    "- `city`: el nombre de una ciudad (por ejemplo, `'Springfield'`).\n",
    "\n",
    "Dentro de la funci√≥n, deber√°s aplicar un **filtrado secuencial mediante indexaci√≥n l√≥gica**: primero tendr√°s que filtrar el DataFrame por el d√≠a, y luego por la ciudad. Una vez que tengas el subconjunto de datos correcto, debes contar cu√°ntas veces aparece un valor en la columna `'user_id'`. Ese n√∫mero representar√° el total de canciones reproducidas bajo esos dos criterios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itD2P5lhEpuX"
   },
   "source": [
    "Etapa 3.5.\n",
    "1. Declara una funci√≥n llamada `number_tracks()` con dos par√°metros: `day` y `city`.\n",
    "\n",
    "2. Filtra el DataFrame para conservar solo las filas donde la columna `'day'` sea igual al valor del par√°metro `day`.\n",
    "\n",
    "3. A partir del resultado anterior, filtra nuevamente para conservar solo las filas donde la columna `'city'` sea igual al valor del par√°metro `city`.\n",
    "\n",
    "4. Extrae la columna `'user_id'` del DataFrame filtrado y utiliza el m√©todo `.count()` para contar el n√∫mero de entradas.\n",
    "\n",
    "5. Guarda ese valor en una variable y **devu√©lvelo** como resultado de la funci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Nz3GdQB1_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id                        track            artist  genre  \\\n",
      "0  FFB692EC            Kamigata To Boots  The Mass Missile   rock   \n",
      "1  55204538  Delayed Because of Accident  Andreas R√∂nnberg   rock   \n",
      "2    20EC38            Funicul√¨ funicul√†       Mario Lanza    pop   \n",
      "3  A3DD03C9        Dragons in the Sunset        Fire + Ice   folk   \n",
      "4  E2DC1FAE                  Soul People        Space Echo  dance   \n",
      "\n",
      "          city      time        day  \n",
      "0  Shelbyville  20:28:33  Wednesday  \n",
      "1  Springfield  14:07:09     Friday  \n",
      "2  Shelbyville  20:58:07  Wednesday  \n",
      "3  Shelbyville  08:37:09     Monday  \n",
      "4  Springfield  08:34:34     Monday  \n"
     ]
    }
   ],
   "source": [
    "def number_tracks(day, city):\n",
    "\n",
    "    # Filtra el DataFrame para el d√≠a y la ciudad especificados, y cuenta las canciones.\n",
    "    track_count = df[(df['day'] == day) & (df['city'] == city)]['track'].count()\n",
    "    return track_count\n",
    "\n",
    "\n",
    "# Limpia los nombres de las columnas: elimina espacios y convierte a min√∫sculas.\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "# Renombra la columna 'userid' a 'user_id'.\n",
    "df = df.rename(columns={'userid': 'user_id'})\n",
    "\n",
    "# Imprime los encabezados del DataFrame para verificar los cambios.\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytf7xFrFJQ2r"
   },
   "source": [
    "Etapa 3.6. Llama a `number_tracks()` seis veces, cambiando los valores de los par√°metros para que puedas recuperar los datos de ambas ciudades para cada uno de los tres d√≠as."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "rJcRATNQ_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de canciones reproducidas en Springfield el lunes: 15740\n"
     ]
    }
   ],
   "source": [
    "# El n√∫mero de canciones reproducidas en Springfield el lunes y lo imprime.\n",
    "reproducciones_lunes_springfield = number_tracks('Monday', 'Springfield')\n",
    "print(\"El n√∫mero de canciones reproducidas en Springfield el lunes:\", reproducciones_lunes_springfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "hq_ncZ5T_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de canciones reproducidas en Shelbyville el lunes: 5614\n"
     ]
    }
   ],
   "source": [
    "# El n√∫mero de canciones reproducidas en Shelbyville el lunes y lo imprime.\n",
    "reproducciones_lunes_shelbyville = number_tracks('Monday', 'Shelbyville')\n",
    "print(\"El n√∫mero de canciones reproducidas en Shelbyville el lunes:\", reproducciones_lunes_shelbyville)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "_NTy2VPU_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de canciones reproducidas en Springfield el mi√©rcoles: 11056\n"
     ]
    }
   ],
   "source": [
    "# El n√∫mero de canciones reproducidas en Springfield el mi√©rcoles y lo imprime.\n",
    "reproducciones_miercoles_springfield = number_tracks('Wednesday', 'Springfield')\n",
    "print(\"El n√∫mero de canciones reproducidas en Springfield el mi√©rcoles:\", reproducciones_miercoles_springfield)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "j2y3TAwo_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de canciones reproducidas en Shelbyville el mi√©rcoles: 7003\n"
     ]
    }
   ],
   "source": [
    "# El n√∫mero de canciones reproducidas en Shelbyville el mi√©rcoles y lo imprime.\n",
    "reproducciones_miercoles_shelbyville = number_tracks('Wednesday', 'Shelbyville')\n",
    "print(\"El n√∫mero de canciones reproducidas en Shelbyville el mi√©rcoles:\", reproducciones_miercoles_shelbyville)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "vYDw5u_K_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de canciones reproducidas en Shelbyville el viernes: 5895\n"
     ]
    }
   ],
   "source": [
    "# Obtiene el n√∫mero de canciones reproducidas en Shelbyville el viernes y lo imprime.\n",
    "reproducciones_viernes_shelbyville = number_tracks('Friday', 'Shelbyville')\n",
    "print(\"El n√∫mero de canciones reproducidas en Shelbyville el viernes:\", reproducciones_viernes_shelbyville)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "8_yzFtW3_Zcu",
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El n√∫mero de canciones reproducidas en Shelbyville el viernes: 5895\n"
     ]
    }
   ],
   "source": [
    "# El n√∫mero de canciones reproducidas en Shelbyville el viernes y lo imprime.\n",
    "reproducciones_viernes_shelbyville = number_tracks('Friday', 'Shelbyville')\n",
    "print(\"El n√∫mero de canciones reproducidas en Shelbyville el viernes:\", reproducciones_viernes_shelbyville)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Conclusiones <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "Escribe tus conclusiones finales sobre la hip√≥tesis.\n",
    "\n",
    " * ¬øLos datos apoyan la idea de que el comportamiento de los usuarios respecto a la m√∫sica que escuchan var√≠a seg√∫n la ciudad y el d√≠a de la semana?\n",
    " * Indica si la hip√≥tesis debe aceptarse o rechazarse, y justifica tu respuesta con base en los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piRc-ATKFwZ3"
   },
   "source": [
    "Etapa 4. Detalla aqu√≠ tus conclusiones.\n",
    "\n",
    "Despu√©s de observar este c√≥digo, compara los n√∫meros de reproducciones para cada ciudad en los diferentes d√≠as. Si los n√∫meros var√≠an significativamente entre ciudades y d√≠as, esto apoyar√≠a la hip√≥tesis de que el comportamiento de los usuarios var√≠a seg√∫n la ciudad y el d√≠a de la semana. Si los n√∫meros son similares, la hip√≥tesis ser√≠a rechazada.\n",
    "\n",
    "Esto sugiere que el comportamiento de los usuarios con respecto a la m√∫sica que escuchan s√≠ var√≠a seg√∫n la ciudad y el d√≠a de la semana. Por lo tanto, se acepta la hip√≥tesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azLHu64yOIp7"
   },
   "source": [
    "### Nota\n",
    "En los proyectos de investigaci√≥n reales, la prueba de hip√≥tesis estad√≠stica es m√°s precisa y cuantitativa. Tambi√©n ten en cuenta que no siempre se pueden sacar conclusiones sobre una ciudad entera a partir de datos de una sola fuente.\n",
    "\n",
    "Aprender√°s m√°s sobre la prueba de hip√≥tesis en el sprint de an√°lisis estad√≠stico de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju4AHDSgV1FE"
   },
   "source": [
    "* [Volver a Contenido](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Hallazgos y Conclusiones del An√°lisis\n",
    "Tras ejecutar el protocolo de an√°lisis comparativo, se validaron los siguientes puntos:\n",
    "\n",
    "1.  **Actividad por D√≠a:** La actividad de los usuarios en Springfield y Shelbyville depende del d√≠a de la semana, pero se comportan de manera opuesta.\n",
    "    * **Lunes y Viernes:** Springfield domina la actividad, mientras que Shelbyville presenta un descenso notable.\n",
    "    * **Mi√©rcoles:** La tendencia se invierte; Shelbyville supera a Springfield en actividad.\n",
    "\n",
    "2.  **Integridad de Datos:** El preprocesamiento de valores ausentes y duplicados fue cr√≠tico para evitar sesgos en el conteo de reproducciones.\n",
    "\n",
    "**Conclusi√≥n Final:** Las estrategias de marketing y recomendaciones musicales no pueden ser uniformes; deben adaptarse al ritmo semanal espec√≠fico de cada ciudad (\"Micro-segmentaci√≥n temporal\")."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 363,
    "start_time": "2025-05-09T19:30:21.637Z"
   },
   {
    "duration": 200,
    "start_time": "2025-05-09T19:35:22.676Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-09T19:35:35.578Z"
   },
   {
    "duration": 5,
    "start_time": "2025-05-09T19:55:33.183Z"
   },
   {
    "duration": 105,
    "start_time": "2025-05-09T19:55:56.579Z"
   },
   {
    "duration": 96,
    "start_time": "2025-05-09T19:59:32.737Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-09T21:35:01.762Z"
   },
   {
    "duration": 108,
    "start_time": "2025-05-09T21:35:19.043Z"
   },
   {
    "duration": 94,
    "start_time": "2025-05-09T21:39:40.394Z"
   },
   {
    "duration": 97,
    "start_time": "2025-05-09T21:42:50.367Z"
   },
   {
    "duration": 103,
    "start_time": "2025-05-09T21:49:34.677Z"
   },
   {
    "duration": 93,
    "start_time": "2025-05-09T21:52:37.024Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-09T21:58:35.579Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-09T21:58:57.010Z"
   },
   {
    "duration": 3,
    "start_time": "2025-05-09T22:00:14.629Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-09T22:00:22.904Z"
   },
   {
    "duration": 102,
    "start_time": "2025-05-09T22:00:43.337Z"
   },
   {
    "duration": 162,
    "start_time": "2025-05-10T04:05:38.815Z"
   },
   {
    "duration": 419,
    "start_time": "2025-05-10T04:08:20.552Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-10T04:09:49.610Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-10T04:10:32.739Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-10T04:11:15.361Z"
   },
   {
    "duration": 7,
    "start_time": "2025-05-10T04:13:54.872Z"
   },
   {
    "duration": 4,
    "start_time": "2025-05-10T04:14:34.655Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-10T04:15:10.898Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-10T04:16:13.470Z"
   },
   {
    "duration": 21,
    "start_time": "2025-05-10T04:17:01.463Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-10T04:17:16.502Z"
   },
   {
    "duration": 22,
    "start_time": "2025-05-10T04:18:01.633Z"
   },
   {
    "duration": 21,
    "start_time": "2025-05-10T04:18:19.259Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-10T04:19:06.017Z"
   },
   {
    "duration": 44,
    "start_time": "2025-05-10T04:20:09.154Z"
   },
   {
    "duration": 41,
    "start_time": "2025-05-10T04:20:26.934Z"
   },
   {
    "duration": 49,
    "start_time": "2025-05-10T04:21:09.061Z"
   },
   {
    "duration": 41,
    "start_time": "2025-05-10T04:21:58.364Z"
   },
   {
    "duration": 8,
    "start_time": "2025-05-10T04:24:23.942Z"
   },
   {
    "duration": 6,
    "start_time": "2025-05-10T05:07:10.882Z"
   },
   {
    "duration": 37,
    "start_time": "2025-05-10T05:07:17.090Z"
   },
   {
    "duration": 13,
    "start_time": "2025-05-10T05:07:58.528Z"
   },
   {
    "duration": 13,
    "start_time": "2025-05-10T05:08:05.491Z"
   },
   {
    "duration": 13,
    "start_time": "2025-05-10T05:18:05.300Z"
   },
   {
    "duration": 156,
    "start_time": "2025-05-10T17:30:06.473Z"
   },
   {
    "duration": 738,
    "start_time": "2025-05-10T17:31:50.097Z"
   },
   {
    "duration": 92,
    "start_time": "2025-05-10T17:33:17.777Z"
   },
   {
    "duration": 95,
    "start_time": "2025-05-10T17:35:04.921Z"
   },
   {
    "duration": 96,
    "start_time": "2025-05-10T17:35:14.405Z"
   },
   {
    "duration": 98,
    "start_time": "2025-05-10T17:35:52.149Z"
   },
   {
    "duration": 113,
    "start_time": "2025-05-10T17:35:59.566Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-10T17:40:59.356Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-10T17:41:10.629Z"
   },
   {
    "duration": 21,
    "start_time": "2025-05-10T17:43:01.612Z"
   },
   {
    "duration": 95,
    "start_time": "2025-05-10T17:55:35.154Z"
   },
   {
    "duration": 93,
    "start_time": "2025-05-10T17:55:38.074Z"
   },
   {
    "duration": 106,
    "start_time": "2025-05-10T17:56:15.509Z"
   },
   {
    "duration": 24,
    "start_time": "2025-05-10T17:56:35.070Z"
   },
   {
    "duration": 108,
    "start_time": "2025-05-10T17:57:05.471Z"
   },
   {
    "duration": 208,
    "start_time": "2025-05-10T18:11:15.307Z"
   },
   {
    "duration": 3,
    "start_time": "2025-05-10T18:14:53.945Z"
   },
   {
    "duration": 99,
    "start_time": "2025-05-10T18:17:14.637Z"
   },
   {
    "duration": 95,
    "start_time": "2025-05-10T18:17:36.431Z"
   },
   {
    "duration": 109,
    "start_time": "2025-05-10T18:29:48.423Z"
   },
   {
    "duration": 103,
    "start_time": "2025-05-10T18:30:50.888Z"
   },
   {
    "duration": 134,
    "start_time": "2025-05-10T18:32:41.829Z"
   },
   {
    "duration": 165,
    "start_time": "2025-05-11T00:44:43.630Z"
   },
   {
    "duration": 160,
    "start_time": "2025-05-11T00:45:23.896Z"
   },
   {
    "duration": 177,
    "start_time": "2025-05-11T00:47:52.732Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:49:36.814Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:51:24.013Z"
   },
   {
    "duration": 17,
    "start_time": "2025-05-11T00:53:25.338Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:53:27.698Z"
   },
   {
    "duration": 14,
    "start_time": "2025-05-11T00:53:29.658Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:53:33.501Z"
   },
   {
    "duration": 11,
    "start_time": "2025-05-11T00:53:36.467Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-11T00:53:42.763Z"
   },
   {
    "duration": 13,
    "start_time": "2025-05-11T00:53:44.541Z"
   },
   {
    "duration": 14,
    "start_time": "2025-05-11T00:53:48.026Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:53:49.874Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-11T00:53:52.121Z"
   },
   {
    "duration": 11,
    "start_time": "2025-05-11T00:53:54.419Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-11T00:53:56.307Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:56:40.911Z"
   },
   {
    "duration": 102,
    "start_time": "2025-05-11T00:57:57.045Z"
   },
   {
    "duration": 142,
    "start_time": "2025-05-11T00:58:59.991Z"
   },
   {
    "duration": 111,
    "start_time": "2025-05-11T00:59:31.117Z"
   },
   {
    "duration": 103,
    "start_time": "2025-05-11T00:59:57.108Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T00:59:59.197Z"
   },
   {
    "duration": 102,
    "start_time": "2025-05-11T01:01:16.289Z"
   },
   {
    "duration": 101,
    "start_time": "2025-05-11T01:02:04.074Z"
   },
   {
    "duration": 106,
    "start_time": "2025-05-11T01:03:53.907Z"
   },
   {
    "duration": 106,
    "start_time": "2025-05-11T01:05:14.236Z"
   },
   {
    "duration": 108,
    "start_time": "2025-05-11T01:06:15.871Z"
   },
   {
    "duration": 147,
    "start_time": "2025-05-11T01:07:00.898Z"
   },
   {
    "duration": 145,
    "start_time": "2025-05-11T01:07:31.687Z"
   },
   {
    "duration": 146,
    "start_time": "2025-05-11T01:07:49.087Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-11T01:08:13.411Z"
   },
   {
    "duration": 15,
    "start_time": "2025-05-11T01:08:18.854Z"
   },
   {
    "duration": 15,
    "start_time": "2025-05-11T01:08:42.049Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-11T01:08:43.639Z"
   },
   {
    "duration": 15,
    "start_time": "2025-05-11T01:08:45.288Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-11T01:08:47.995Z"
   },
   {
    "duration": 12,
    "start_time": "2025-05-11T01:08:48.659Z"
   },
   {
    "duration": 13,
    "start_time": "2025-05-11T01:08:55.585Z"
   },
   {
    "duration": 10,
    "start_time": "2025-05-12T01:46:46.003Z"
   },
   {
    "duration": 16,
    "start_time": "2025-05-12T01:47:08.084Z"
   },
   {
    "duration": 481,
    "start_time": "2025-05-12T01:48:30.636Z"
   },
   {
    "duration": 7,
    "start_time": "2025-05-12T01:59:16.366Z"
   },
   {
    "duration": 114,
    "start_time": "2025-05-12T02:11:14.161Z"
   }
  ],
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
